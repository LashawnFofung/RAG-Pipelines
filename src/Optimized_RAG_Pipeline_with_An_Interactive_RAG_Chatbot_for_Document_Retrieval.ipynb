{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/E70GHPThi7EPUPVsQNss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LashawnFofung/RAG-Pipelines/blob/main/src/Optimized_RAG_Pipeline_with_An_Interactive_RAG_Chatbot_for_Document_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìù Optimized RAG Pipeline with An Interactive RAG Chatbot For Document Retrieval**\n",
        "\n",
        "**Data:** *LenderFeesWorksheetNew.pdf*\n",
        "<br><br>\n",
        "\n",
        "\n",
        "This Colab notebook sets up a complete, interactive Retrieval-Augmented Generation (RAG) system designed to function as a powerful chatbot for answering questions grounded in the uploaded LenderFeesWorksheetNew.pdf.\n",
        "<br><br>\n",
        "\n",
        "The pipeline works by first using PyMuPDF to accurately extract (parse) the text from the PDF. This text is then broken down into smaller, meaningful chunks (‚úÇÔ∏è) and converted into numerical vectors (üî¢) using the efficient all-MiniLM-L6-v2 HuggingFace embedding model. These vectors are stored in a Vector Index.\n",
        "<br><br>\n",
        "\n",
        "The Interactive RAG Chatbot leverages this index. When you ask a question, the system searches the index to retrieve (üîç) the most relevant text chunks (Vector Retrieval). These retrieved chunks‚Äîalong with the conversation history‚Äîare then fed to the Gemini 2.5 Flash LLM. The LLM reads the contextual information and generates a precise, grounded answer, allowing you to ask follow-up questions about calculating the total monthly payment or identifying specific fees.\n",
        "<br><br>\n",
        "\n",
        "\n",
        "**Table of Contents**\n",
        "* [1. RAG Pipeline](#scrollTo=Bfr8FNjnSvW8&line=1&uniqifier=1)\n",
        "  * [1.1 Installation](#scrollTo=CVLftbBrTtJD&line=1&uniqifier=1)\n",
        "  * [1.2 Setup Environment and Imports](#scrollTo=A-7Tha4LT_Wp&line=1&uniqifier=1)\n",
        "  * [1.3 API Key Setup](#scrollTo=p43QyjfpUZ-k&line=1&uniqifier=1)\n",
        "  * [1.4 Document Upload](#scrollTo=zF41iRd_UmH7&line=1&uniqifier=1)\n",
        "  * [1.5 Custom PyMuPDF Loader Function (PDF Parsing)](#scrollTo=bh0AOQB7nvmp&line=1&uniqifier=1)\n",
        "  * [1.6 Configure RAG Pipeline (LLM, Embedding, Chunking)](#scrollTo=YqYMeoCroEGh&line=1&uniqifier=1)\n",
        "  * [1.7 Indexing and Index Creation](#scrollTo=7F7-so82oU_z&line=1&uniqifier=1)\n",
        "* [2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method](#scrollTo=2lo9ffUJSzJE&line=1&uniqifier=1)\n",
        "* [3. Simple Chatbot](#scrollTo=KZt_12xPS5hx)\n",
        "  * [3.1 Create Chat Engine](#scrollTo=B_9DrGkNxFQr&line=1&uniqifier=1)\n",
        "  * [3.2 Interactive Chat Loop](#scrollTo=zxAruhrJyeHa&line=1&uniqifier=1)\n",
        "  * [3.3 Run the Chatbot](#scrollTo=wIfn7bGazZ7k&line=1&uniqifier=1)\n",
        "  "
      ],
      "metadata": {
        "id": "6PmIjtzqPkDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. RAG Pipeline**"
      ],
      "metadata": {
        "id": "Bfr8FNjnSvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Installation"
      ],
      "metadata": {
        "id": "CVLftbBrTtJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LlamaIndex core, Gemini LLM connector, PyMuPDF, and HuggingFace Embedding integration\n",
        "!pip install -q llama-index llama-index-llms-gemini pymupdf llama-index-embeddings-huggingface nest_asyncio sentence-transformers"
      ],
      "metadata": {
        "id": "H8BUJNkyT0LC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Setup Environment and Imports"
      ],
      "metadata": {
        "id": "A-7Tha4LT_Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz # PyMuPDF\n",
        "from google.colab import files, userdata\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from typing import List\n",
        "import nest_asyncio\n",
        "\n",
        "# Fix event loop conflicts in Colab\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "9M0_WDziUJjO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 API Key Setup"
      ],
      "metadata": {
        "id": "p43QyjfpUZ-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Gemini API Key setup in Colab secret\n",
        "try:\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not API_KEY:\n",
        "        raise ValueError(\"GEMINI_API_KEY not found in Colab Secrets. Please set it.\")\n",
        "    # Set the official environment variable name required by the Google GenAI SDK\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = API_KEY\n",
        "    print(\"‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\")\n",
        "\n",
        "\n",
        "# 2. Hugging Face API Token\n",
        "    HF_TOKEN = userdata.get('HFACE_API_KEY')\n",
        "    if HF_TOKEN:\n",
        "        os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "        print(\"‚úÖ Hugging Face API Token loaded.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: Hugging Face API Key not found. Hugging Face models requiring auth may fail.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Warning: Could not load API Key from Colab Secrets: {e}\")\n",
        "    print(\"Please ensure your API Key is set as a Colab secret named or set the environment variable manually.\")\n",
        "    # Fallback/Manual setting (Uncomment and replace if Colab Secrets is not used)\n",
        "    # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_MANUAL_API_KEY\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0InllCONUggj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ba7019-30ec-4927-eff7-6483c66947af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\n",
            "‚úÖ Hugging Face API Token loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Document Upload"
      ],
      "metadata": {
        "id": "zF41iRd_UmH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = None\n",
        "if uploaded:\n",
        "    pdf_path = list(uploaded.keys())[0]\n",
        "    print(f\"Successfully uploaded: {pdf_path}\")\n",
        "else:\n",
        "    print(\"No file was uploaded. Exiting.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "BjWKUUkIUp6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "b532fd43-b30f-4e4a-d6d2-7fa34adfc8b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22640a70-c428-456d-ab49-4e9563c6e347\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22640a70-c428-456d-ab49-4e9563c6e347\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving LenderFeesWorksheetNew.pdf to LenderFeesWorksheetNew (6).pdf\n",
            "Successfully uploaded: LenderFeesWorksheetNew (6).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Custom PyMuPDF Loader Function (PDF Parsing)"
      ],
      "metadata": {
        "id": "bh0AOQB7nvmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_with_pymupdf(pdf_path: str) -> List[Document]:\n",
        "    \"\"\"Load a PDF and convert it to LlamaIndex Document format using PyMuPDF.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    documents = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "        if not text.strip(): continue # Skip empty pages\n",
        "        documents.append(\n",
        "            Document(text=text, metadata={\"file_name\": os.path.basename(pdf_path), \"page_number\": i + 1})\n",
        "        )\n",
        "    doc.close()\n",
        "    print(f\"Processed {pdf_path}: Extracted {len(documents)} pages with content.\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "H0kFuz4Rn7Q3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Configure RAG Pipeline (LLM, Embeddings, Chunking)"
      ],
      "metadata": {
        "id": "YqYMeoCroEGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Configuring LlamaIndex Settings ---\")\n",
        "# LLM: Gemini 2.5 Flash\n",
        "llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
        "Settings.llm = llm\n",
        "\n",
        "# Embedding Model: HuggingFace all-MiniLM-L6-v2 (Efficient and Local)\n",
        "# Hugging Face API Key setup in Colab Secret\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Chunking Strategy: SentenceSplitter with optimal settings\n",
        "Settings.text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "id": "5mtgoZ_aoNqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7ab1d2ee-79b2-4f60-a93f-a88306424865"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Configuring LlamaIndex Settings ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1179820267.py:3: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  llm = Gemini(model=\"models/gemini-2.5-flash\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Indexing and Index Creation"
      ],
      "metadata": {
        "id": "7F7-so82oU_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_pdf_with_pymupdf(pdf_path)\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "print(\"‚úÖ Indexing complete. RAG VectorStoreIndex created.\")"
      ],
      "metadata": {
        "id": "pvoRfyFRog9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5baf210a-71e6-4fda-dac6-1135f9b40e67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed LenderFeesWorksheetNew (6).pdf: Extracted 1 pages with content.\n",
            "‚úÖ Indexing complete. RAG VectorStoreIndex created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method**"
      ],
      "metadata": {
        "id": "2lo9ffUJSzJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üî¢ Embedding Model**\n",
        "\n",
        "**Model:** `sentence-transformers/all-MiniLM-L6-v2`\n",
        "<br><br>\n",
        "\n",
        "**Justification:** This model is an extremely efficient, small, and fast open-source embedding model. It provides a good balance of accuracy and speed, making it highly suitable for rapid RAG development in a Colab environment. Running a local HuggingFace model also helps to reduce API costs and latency compared to calling a remote embedding service.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ggWcI5nj0vzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **‚úÇÔ∏è Chunking Strategy**\n",
        "\n",
        "**Strategy:** `SentenceSplitter` with `chunk_size = 512` and `chunk_overlap = 20`.\n",
        "<br><br>\n",
        "\n",
        "**Justification:** The `SentenceSplitter` breaks text primarily at logical sentence boundaries, which is ideal for a semi-structured document like a financial worksheet.\n",
        "\n",
        "  * **Chunk Size (512 tokens):** Provides enough context for the LLM to perform calculations or detailed analysis from the retrieved text.\n",
        "  \n",
        "  * **Overlap (20 tokens):** A small overlap ensures that the context is maintained across the split points, preventing critical information from being cut off.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoIn097P19eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üîç Retrieval Method**\n",
        "\n",
        "**Method:** **Vector Retrieval** (Semantic Search)\n",
        "<br><br>\n",
        "\n",
        "**Justification:** Vector retrieval is used because it finds relevant document segments based on the semantic mening of the query. This is essential for documents where specific financial terms might be used (e.g., \"lender's title insurance\") that a user might query using a different phrase (e.g., \"fee to protect the lender's interest\").\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kFxgX4_l3Zwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Create Query Engine and Execute Prompts**"
      ],
      "metadata": {
        "id": "KZt_12xPS5hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Create Chat Engine"
      ],
      "metadata": {
        "id": "B_9DrGkNxFQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the ChatEngine to maintain conversation history while retrieving context\n",
        "# from your index for each turn.\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"condense_plus_context\", # A common mode for RAG chat\n",
        "    similarity_top_k=3\n",
        ")"
      ],
      "metadata": {
        "id": "DpwmuqyAxL9k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Interactive Chat Loop"
      ],
      "metadata": {
        "id": "zxAruhrJyeHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_rag_chatbot():\n",
        "    \"\"\"\n",
        "    An interactive chatbot that grounds its answers using the RAG pipeline.\n",
        "    \"\"\"\n",
        "    # Initial setup message printed once\n",
        "    print(\"\\n--- üí¨ Interactive RAG Chatbot üí¨ ---\")\n",
        "    print(f\"Document: {pdf_path}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    while True:\n",
        "        # --- Message with instructions for user to ask chatbot ---\n",
        "        print(\"üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        try:\n",
        "            # Use input() within a try/except to handle unexpected Colab issues\n",
        "            user_input = input(\"You: \")\n",
        "        except EOFError:\n",
        "            # This often catches issues when input is expected but not provided interactively\n",
        "            print(\"\\nExiting due to non-interactive environment.\")\n",
        "            break\n",
        "\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"\\nChatbot: Goodbye! Feel free to upload a new document next time.\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # Use the chat_engine which handles history and retrieval simultaneously\n",
        "            response = chat_engine.chat(user_input)\n",
        "\n",
        "            # Print the response\n",
        "            print(f\"\\nChatbot: {response.response}\")\n",
        "\n",
        "            # >>> ADDED SEPARATOR HERE <<<\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing query: {e}\")\n",
        "            print(\"Please try again.\")"
      ],
      "metadata": {
        "id": "reFbq0GZyc9K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Run the chatbot"
      ],
      "metadata": {
        "id": "wIfn7bGazZ7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_rag_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6xhwdwTzgo0",
        "outputId": "1e354e6f-5b45-435b-8f72-8d20f74d6d50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üí¨ Interactive RAG Chatbot üí¨ ---\n",
            "Document: LenderFeesWorksheetNew (5).pdf\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: what is the total estimated monthly payment\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (5).pdf\" document, the total estimated monthly payment is **$1,869.37**.\n",
            "\n",
            "This figure is explicitly stated under the \"Fee Details and Summary\" section on page 1 of the document as:\n",
            "*   **TOTAL ESTIMATED MONTHLY PAYMENT:** $1,869.37\n",
            "\n",
            "The document also provides a breakdown of potential monthly payment components, where the Principal & Interest portion matches this total:\n",
            "*   **Principal & Interest:** $1,869.37\n",
            "*   **Other Financing (P & I):** $39.58\n",
            "*   **Hazard Insurance:** $400.00\n",
            "*   **Real Estate Taxes:** $2,308.95\n",
            "*   **Mortgage Insurance:** (No amount listed)\n",
            "*   **Homeowner Assn. Dues:** (No amount listed)\n",
            "*   **Other:** (No amount listed)\n",
            "\n",
            "It's worth noting that the \"TOTAL ESTIMATED MONTHLY PAYMENT\" of $1,869.37 specifically refers to the Principal & Interest portion of the loan. Other items like Hazard Insurance and Real Estate Taxes are listed as separate monthly costs that would contribute to the overall housing expense but are not included in the stated \"TOTAL ESTIMATED MONTHLY PAYMENT\" figure.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: lender's title insurance\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (5).pdf\" document, here are the details for the Lender's Title Insurance:\n",
            "\n",
            "*   **Fee Name:** Lender's Title Insurance\n",
            "*   **Paid To:** (Not specified in the \"Paid To\" column, but it's a type of insurance)\n",
            "*   **Paid By:** Borrower\n",
            "*   **Amount:** $650.00\n",
            "\n",
            "This fee is listed among the various charges that the borrower is responsible for.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: fee to protect the lender's interest\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (5).pdf\" document, the fee that is explicitly designed to protect the lender's interest is the **Lender's Title Insurance**.\n",
            "\n",
            "Here are the details for this fee:\n",
            "\n",
            "*   **Fee Name:** Lender's Title Insurance\n",
            "*   **Paid To:** (Not specified in the \"Paid To\" column, but it's a type of insurance that protects the lender against losses arising from defects in the title to the property)\n",
            "*   **Paid By:** Borrower\n",
            "*   **Amount:** $650.00\n",
            "\n",
            "While other fees like the **Mortgage Recording Charge** (which records the lender's lien on the property) and the **Tax Service Fee** (which ensures property taxes are paid, preventing a superior lien) also indirectly protect the lender's interest, the **Lender's Title Insurance** is specifically named for this purpose in the context of title defects.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: bus price\n",
            "\n",
            "Chatbot: I'm sorry, but the provided documents, \"LenderFeesWorksheetNew (5).pdf\", do not contain any information about a \"bus price\". The documents detail various fees and charges related to a loan, such as a purchase price for a property, closing costs, and monthly payments, but there is no mention of a bus price.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: date of payment\n",
            "\n",
            "Chatbot: I'm sorry, but the provided document, \"LenderFeesWorksheetNew (5).pdf\", does not specify a \"date of payment\" for the estimated monthly mortgage payment or for any of the individual fees listed.\n",
            "\n",
            "The document does include a \"Date Prepared\" which is **10/05/2015**, but this is the date the worksheet itself was created, not a payment due date. It also mentions \"Term/Due In: 360 / 360 mths\" which refers to the loan's duration, but not a specific monthly payment date.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: exit\n",
            "\n",
            "Chatbot: Goodbye! Feel free to upload a new document next time.\n"
          ]
        }
      ]
    }
  ]
}