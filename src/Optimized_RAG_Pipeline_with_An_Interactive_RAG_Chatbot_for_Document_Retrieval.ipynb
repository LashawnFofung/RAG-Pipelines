{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkqaXIKZFTsDW1uW/ReiXK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LashawnFofung/RAG-Pipelines/blob/main/src/Optimized_RAG_Pipeline_with_An_Interactive_RAG_Chatbot_for_Document_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìù Optimized RAG Pipeline with An Interactive RAG Chatbot For Document Retrieval**\n",
        "\n",
        "**Data:** *LenderFeesWorksheetNew.pdf*\n",
        "<br><br>\n",
        "\n",
        "\n",
        "This Colab notebook sets up a complete, interactive Retrieval-Augmented Generation (RAG) system designed to function as a powerful chatbot for answering questions grounded in the uploaded LenderFeesWorksheetNew.pdf.\n",
        "<br><br>\n",
        "\n",
        "The pipeline works by first using PyMuPDF to accurately extract (parse) the text from the PDF. This text is then broken down into smaller, meaningful chunks (‚úÇÔ∏è) and converted into numerical vectors (üî¢) using the efficient all-MiniLM-L6-v2 HuggingFace embedding model. These vectors are stored in a Vector Index.\n",
        "<br><br>\n",
        "\n",
        "The Interactive RAG Chatbot leverages this index. When you ask a question, the system searches the index to retrieve (üîç) the most relevant text chunks (Vector Retrieval). These retrieved chunks‚Äîalong with the conversation history‚Äîare then fed to the Gemini 2.5 Flash LLM. The LLM reads the contextual information and generates a precise, grounded answer, allowing you to ask follow-up questions about calculating the total monthly payment or identifying specific fees.\n",
        "<br><br>\n",
        "\n",
        "\n",
        "**Table of Contents**\n",
        "* [1. RAG Pipeline](#scrollTo=Bfr8FNjnSvW8&line=1&uniqifier=1)\n",
        "  * [1.1 Installation](#scrollTo=CVLftbBrTtJD&line=1&uniqifier=1)\n",
        "  * [1.2 Setup Environment and Imports](#scrollTo=A-7Tha4LT_Wp&line=1&uniqifier=1)\n",
        "  * [1.3 API Key Setup](#scrollTo=p43QyjfpUZ-k&line=1&uniqifier=1)\n",
        "  * [1.4 Document Upload](#scrollTo=zF41iRd_UmH7&line=1&uniqifier=1)\n",
        "  * [1.5 Custom PyMuPDF Loader Function (PDF Parsing)](#scrollTo=bh0AOQB7nvmp&line=1&uniqifier=1)\n",
        "  * [1.6 Configure RAG Pipeline (LLM, Embedding, Chunking)](#scrollTo=YqYMeoCroEGh&line=1&uniqifier=1)\n",
        "  * [1.7 Indexing and Index Creation](#scrollTo=7F7-so82oU_z&line=1&uniqifier=1)\n",
        "* [2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method](#scrollTo=2lo9ffUJSzJE&line=1&uniqifier=1)\n",
        "* [3. Simple Chatbot](#scrollTo=KZt_12xPS5hx)\n",
        "  * [3.1 Create Chat Engine](#scrollTo=B_9DrGkNxFQr&line=1&uniqifier=1)\n",
        "  * [3.2 Interactive Chat Loop](#scrollTo=zxAruhrJyeHa&line=1&uniqifier=1)\n",
        "  * [3.3 Run the Chatbot](#scrollTo=wIfn7bGazZ7k&line=1&uniqifier=1)\n",
        "  "
      ],
      "metadata": {
        "id": "6PmIjtzqPkDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. RAG Pipeline**"
      ],
      "metadata": {
        "id": "Bfr8FNjnSvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Installation"
      ],
      "metadata": {
        "id": "CVLftbBrTtJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LlamaIndex core, Gemini LLM connector, PyMuPDF, and HuggingFace Embedding integration\n",
        "!pip install -q llama-index llama-index-llms-gemini pymupdf llama-index-embeddings-huggingface nest_asyncio sentence-transformers"
      ],
      "metadata": {
        "id": "H8BUJNkyT0LC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Setup Environment and Imports"
      ],
      "metadata": {
        "id": "A-7Tha4LT_Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz # PyMuPDF\n",
        "from google.colab import files, userdata\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from typing import List\n",
        "import nest_asyncio\n",
        "\n",
        "# Fix event loop conflicts in Colab\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "9M0_WDziUJjO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 API Key Setup"
      ],
      "metadata": {
        "id": "p43QyjfpUZ-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Gemini API Key setup in Colab secret\n",
        "try:\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not API_KEY:\n",
        "        raise ValueError(\"GEMINI_API_KEY not found in Colab Secrets. Please set it.\")\n",
        "    # Set the official environment variable name required by the Google GenAI SDK\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = API_KEY\n",
        "    print(\"‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\")\n",
        "\n",
        "\n",
        "# 2. Hugging Face API Token\n",
        "    HFACE_TOKEN = userdata.get('HFACE_API_KEY')\n",
        "    if HFACE_TOKEN:\n",
        "        os.environ[\"HFACE_TOKEN\"] = HFACE_TOKEN\n",
        "        print(\"‚úÖ Hugging Face API Token loaded.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Warning: HFACE_API_KEY not found. Hugging Face models requiring auth may fail.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Warning: Could not load API Key from Colab Secrets: {e}\")\n",
        "    print(\"Please ensure your API Key is set as a Colab secret named 'GEMINI_API_KEY' or set the environment variable manually.\")\n",
        "    # Fallback/Manual setting (Uncomment and replace if Colab Secrets is not used)\n",
        "    # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_MANUAL_API_KEY\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0InllCONUggj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745bc434-422c-4c92-9e8f-7a81b75ea43d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\n",
            "‚úÖ Hugging Face API Token loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Document Upload"
      ],
      "metadata": {
        "id": "zF41iRd_UmH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = None\n",
        "if uploaded:\n",
        "    pdf_path = list(uploaded.keys())[0]\n",
        "    print(f\"Successfully uploaded: {pdf_path}\")\n",
        "else:\n",
        "    print(\"No file was uploaded. Exiting.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "BjWKUUkIUp6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "f2e5a817-5a7d-45bb-d978-13acae3dc0d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8451d210-4e9e-4f9a-ad48-71ae4421aecc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8451d210-4e9e-4f9a-ad48-71ae4421aecc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving LenderFeesWorksheetNew.pdf to LenderFeesWorksheetNew (3).pdf\n",
            "Successfully uploaded: LenderFeesWorksheetNew (3).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Custom PyMuPDF Loader Function (PDF Parsing)"
      ],
      "metadata": {
        "id": "bh0AOQB7nvmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_with_pymupdf(pdf_path: str) -> List[Document]:\n",
        "    \"\"\"Load a PDF and convert it to LlamaIndex Document format using PyMuPDF.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    documents = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "        if not text.strip(): continue # Skip empty pages\n",
        "        documents.append(\n",
        "            Document(text=text, metadata={\"file_name\": os.path.basename(pdf_path), \"page_number\": i + 1})\n",
        "        )\n",
        "    doc.close()\n",
        "    print(f\"Processed {pdf_path}: Extracted {len(documents)} pages with content.\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "H0kFuz4Rn7Q3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Configure RAG Pipeline (LLM, Embeddings, Chunking)"
      ],
      "metadata": {
        "id": "YqYMeoCroEGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Configuring LlamaIndex Settings ---\")\n",
        "# LLM: Gemini 2.5 Flash\n",
        "llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
        "Settings.llm = llm\n",
        "\n",
        "# Embedding Model: HuggingFace all-MiniLM-L6-v2 (Efficient and Local)\n",
        "# Hugging Face API Key setup in Colab Secret\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Chunking Strategy: SentenceSplitter with optimal settings\n",
        "Settings.text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "id": "5mtgoZ_aoNqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "fbce600c-2fdc-4642-fe4b-c3f09f13b113"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Configuring LlamaIndex Settings ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1179820267.py:3: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Indexing and Index Creation"
      ],
      "metadata": {
        "id": "7F7-so82oU_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_pdf_with_pymupdf(pdf_path)\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "print(\"‚úÖ Indexing complete. RAG VectorStoreIndex created.\")"
      ],
      "metadata": {
        "id": "pvoRfyFRog9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0244980-0fd6-4280-e19e-1719208b8ddc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed LenderFeesWorksheetNew (3).pdf: Extracted 1 pages with content.\n",
            "‚úÖ Indexing complete. RAG VectorStoreIndex created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method**"
      ],
      "metadata": {
        "id": "2lo9ffUJSzJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üî¢ Embedding Model**\n",
        "\n",
        "**Model:** `sentence-transformers/all-MiniLM-L6-v2`\n",
        "<br><br>\n",
        "\n",
        "**Justification:** This model is an extremely efficient, small, and fast open-source embedding model. It provides a good balance of accuracy and speed, making it highly suitable for rapid RAG development in a Colab environment. Running a local HuggingFace model also helps to reduce API costs and latency compared to calling a remote embedding service.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ggWcI5nj0vzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **‚úÇÔ∏è Chunking Strategy**\n",
        "\n",
        "**Strategy:** `SentenceSplitter` with `chunk_size = 512` and `chunk_overlap = 20`.\n",
        "<br><br>\n",
        "\n",
        "**Justification:** The `SentenceSplitter` breaks text primarily at logical sentence boundaries, which is ideal for a semi-structured document like a financial worksheet.\n",
        "\n",
        "  * **Chunk Size (512 tokens):** Provides enough context for the LLM to perform calculations or detailed analysis from the retrieved text.\n",
        "  \n",
        "  * **Overlap (20 tokens):** A small overlap ensures that the context is maintained across the split points, preventing critical information from being cut off.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoIn097P19eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üîç Retrieval Method**\n",
        "\n",
        "**Method:** **Vector Retrieval** (Semantic Search)\n",
        "<br><br>\n",
        "\n",
        "**Justification:** Vector retrieval is used because it finds relevant document segments based on the semantic mening of the query. This is essential for documents where specific financial terms might be used (e.g., \"lender's title insurance\") that a user might query using a different phrase (e.g., \"fee to protect the lender's interest\").\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kFxgX4_l3Zwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Create Query Engine and Execute Prompts**"
      ],
      "metadata": {
        "id": "KZt_12xPS5hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Create Chat Engine"
      ],
      "metadata": {
        "id": "B_9DrGkNxFQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the ChatEngine to maintain conversation history while retrieving context\n",
        "# from your index for each turn.\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"condense_plus_context\", # A common mode for RAG chat\n",
        "    similarity_top_k=3\n",
        ")"
      ],
      "metadata": {
        "id": "DpwmuqyAxL9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Interactive Chat Loop"
      ],
      "metadata": {
        "id": "zxAruhrJyeHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_rag_chatbot():\n",
        "    \"\"\"\n",
        "    An interactive chatbot that grounds its answers using the RAG pipeline.\n",
        "    \"\"\"\n",
        "    # Initial setup message printed once\n",
        "    print(\"\\n--- üí¨ Interactive RAG Chatbot üí¨ ---\")\n",
        "    print(f\"Document: {pdf_path}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    while True:\n",
        "        # --- Message with instructions for user to ask chatbot ---\n",
        "        print(\"üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        try:\n",
        "            # Use input() within a try/except to handle unexpected Colab issues\n",
        "            user_input = input(\"You: \")\n",
        "        except EOFError:\n",
        "            # This often catches issues when input is expected but not provided interactively\n",
        "            print(\"\\nExiting due to non-interactive environment.\")\n",
        "            break\n",
        "\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"\\nChatbot: Goodbye! Feel free to upload a new document next time.\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # Use the chat_engine which handles history and retrieval simultaneously\n",
        "            response = chat_engine.chat(user_input)\n",
        "\n",
        "            # Print the response\n",
        "            print(f\"\\nChatbot: {response.response}\")\n",
        "\n",
        "            # >>> ADDED SEPARATOR HERE <<<\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing query: {e}\")\n",
        "            print(\"Please try again.\")"
      ],
      "metadata": {
        "id": "reFbq0GZyc9K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Run the chatbot"
      ],
      "metadata": {
        "id": "wIfn7bGazZ7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_rag_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6xhwdwTzgo0",
        "outputId": "6cb9d8a6-61dd-4129-d31b-4f34e6d0286b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üí¨ Interactive RAG Chatbot üí¨ ---\n",
            "Document: LenderFeesWorksheetNew (3).pdf\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: what is the total estimated montly payment\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (3).pdf\" document, the **Total Estimated Monthly Payment** is **$2,308.95**.\n",
            "\n",
            "This estimated monthly payment is composed of the following items:\n",
            "*   **Principal & Interest:** $1,869.37\n",
            "*   **Hazard Insurance:** $39.58\n",
            "*   **Real Estate Taxes:** $400.00\n",
            "*   **Mortgage Insurance:** $0.00\n",
            "*   **Homeowner Assn. Dues:** $0.00\n",
            "*   **Other:** $0.00\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: lender's title insurance\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (3).pdf\" document, here are the specific details regarding the **Lender's Title Insurance**:\n",
            "\n",
            "*   **Amount:** $650.00\n",
            "*   **Paid By:** Borrower\n",
            "*   **Paid To:** The document does not explicitly state who the Lender's Title Insurance is paid to.\n",
            "\n",
            "To provide a bit more context, Lender's Title Insurance is a crucial component in a real estate transaction. Its primary purpose is to protect the lender's financial investment in the property. It safeguards the lender against potential losses that could arise from various defects in the property's title, such as:\n",
            "*   Undisclosed liens (e.g., unpaid mortgages, tax liens, or judgments)\n",
            "*   Errors or omissions in public records\n",
            "*   Fraud or forgery in previous title documents\n",
            "*   Claims by unknown heirs\n",
            "*   Improperly executed documents\n",
            "\n",
            "Essentially, it ensures that the lender's mortgage is a valid and enforceable lien on the property, giving them peace of mind that their collateral is secure.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: fee to protect the lender's interest\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (3).pdf\" document, there are several fees listed that directly or indirectly serve to protect the lender's interest in the loan and the property that secures it.\n",
            "\n",
            "The most direct fee specifically designed to protect the lender's interest is the **Lender's Title Insurance**.\n",
            "*   **Lender's Title Insurance:**\n",
            "    *   **Amount:** $650.00\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Purpose:** This insurance protects the lender against financial losses that could arise from defects in the title to the property. This includes issues like undisclosed liens, errors in public records, or claims of ownership by others, ensuring the lender's mortgage is a valid and enforceable lien.\n",
            "\n",
            "In addition to Lender's Title Insurance, several other fees contribute significantly to protecting the lender's interest by assessing the collateral, the borrower's ability to repay, or the legal standing of the loan:\n",
            "\n",
            "*   **Appraisal Fee:**\n",
            "    *   **Amount:** $525.00\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Purpose:** This fee covers the cost of an independent appraisal to determine the property's market value. This is crucial for the lender to ensure that the property provides sufficient collateral for the loan amount, protecting their investment in case of default.\n",
            "\n",
            "*   **Tax Service Fee:**\n",
            "    *   **Amount:** $80.00\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Purpose:** This fee pays for a service that monitors the payment of property taxes. Unpaid property taxes can result in a tax lien that takes priority over the lender's mortgage lien, so this service helps protect the lender's primary lien position.\n",
            "\n",
            "*   **Mortgage Recording Charge:**\n",
            "    *   **Amount:** $150.00\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Purpose:** This fee is for officially recording the mortgage document with the local government authority. Recording the mortgage legally establishes the lender's lien on the property, which is fundamental for protecting their interest and their ability to enforce the loan terms.\n",
            "\n",
            "*   **Credit Report Fee:**\n",
            "    *   **Amount:** $25.00\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Purpose:** This fee covers the cost of obtaining the borrower's credit report. The credit report provides the lender with an assessment of the borrower's creditworthiness and their history of repaying debts, which is vital for evaluating the risk of default.\n",
            "\n",
            "*   **Flood Certification Fee:**\n",
            "    *   **Amount:** $20.00\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Purpose:** This fee is for determining if the property is located in a designated flood hazard area. If it is, the lender will typically require flood insurance, which protects the property (and thus the lender's collateral) from potential damage due to flooding.\n",
            "------------------------------------------------------------\n",
            "üü¢ Ask Chatbot questions about the document or üî¥ Type  'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: exit\n",
            "\n",
            "Chatbot: Goodbye! Feel free to upload a new document next time.\n"
          ]
        }
      ]
    }
  ]
}