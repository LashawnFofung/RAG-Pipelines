{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGiRqk+hRhflY0PFT/XDQl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LashawnFofung/RAG-Pipelines/blob/main/src/Optimized_RAG_Pipeline_with_An_Interactive_RAG_Chatbot_for_Document_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìù Optimized RAG Pipeline with An Interactive RAG Chatbot For Document Retrieval**\n",
        "\n",
        "**Data:** *LenderFeesWorksheetNew.pdf*\n",
        "<br><br>\n",
        "\n",
        "\n",
        "This Colab notebook sets up a complete, interactive Retrieval-Augmented Generation (RAG) system designed to function as a powerful chatbot for answering questions grounded in the uploaded LenderFeesWorksheetNew.pdf.\n",
        "<br><br>\n",
        "\n",
        "The pipeline works by first using PyMuPDF to accurately extract (parse) the text from the PDF. This text is then broken down into smaller, meaningful chunks (‚úÇÔ∏è) and converted into numerical vectors (üî¢) using the efficient all-MiniLM-L6-v2 HuggingFace embedding model. These vectors are stored in a Vector Index.\n",
        "<br><br>\n",
        "\n",
        "The Interactive RAG Chatbot leverages this index. When you ask a question, the system searches the index to retrieve (üîç) the most relevant text chunks (Vector Retrieval). These retrieved chunks‚Äîalong with the conversation history‚Äîare then fed to the Gemini 2.5 Flash LLM. The LLM reads the contextual information and generates a precise, grounded answer, allowing you to ask follow-up questions about calculating the total monthly payment or identifying specific fees.\n",
        "<br><br>\n",
        "\n",
        "\n",
        "**Table of Contents**\n",
        "* [1. RAG Pipeline](#scrollTo=Bfr8FNjnSvW8&line=1&uniqifier=1)\n",
        "  * [1.1 Installation](#scrollTo=CVLftbBrTtJD&line=1&uniqifier=1)\n",
        "  * [1.2 Setup Environment and Imports](#scrollTo=A-7Tha4LT_Wp&line=1&uniqifier=1)\n",
        "  * [1.3 API Key Setup](#scrollTo=p43QyjfpUZ-k&line=1&uniqifier=1)\n",
        "  * [1.4 Document Upload](#scrollTo=zF41iRd_UmH7&line=1&uniqifier=1)\n",
        "  * [1.5 Custom PyMuPDF Loader Function (PDF Parsing)](#scrollTo=bh0AOQB7nvmp&line=1&uniqifier=1)\n",
        "  * [1.6 Configure RAG Pipeline (LLM, Embedding, Chunking)](#scrollTo=YqYMeoCroEGh&line=1&uniqifier=1)\n",
        "  * [1.7 Indexing and Index Creation](#scrollTo=7F7-so82oU_z&line=1&uniqifier=1)\n",
        "* [2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method](#scrollTo=2lo9ffUJSzJE&line=1&uniqifier=1)\n",
        "* [3. Simple Chatbot](#scrollTo=KZt_12xPS5hx)\n",
        "  * [3.1 Create Chat Engine](#scrollTo=B_9DrGkNxFQr&line=1&uniqifier=1)\n",
        "  * [3.2 Interactive Chat Loop](#scrollTo=zxAruhrJyeHa&line=1&uniqifier=1)\n",
        "  * [3.3 Run the Chatbot](#scrollTo=wIfn7bGazZ7k&line=1&uniqifier=1)\n",
        "  "
      ],
      "metadata": {
        "id": "6PmIjtzqPkDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. RAG Pipeline**"
      ],
      "metadata": {
        "id": "Bfr8FNjnSvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Installation"
      ],
      "metadata": {
        "id": "CVLftbBrTtJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LlamaIndex core, Gemini LLM connector, PyMuPDF, and HuggingFace Embedding integration\n",
        "!pip install -q llama-index llama-index-llms-gemini pymupdf llama-index-embeddings-huggingface nest_asyncio sentence-transformers"
      ],
      "metadata": {
        "id": "H8BUJNkyT0LC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Setup Environment and Imports"
      ],
      "metadata": {
        "id": "A-7Tha4LT_Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz # PyMuPDF\n",
        "from google.colab import files, userdata\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from typing import List\n",
        "import nest_asyncio\n",
        "\n",
        "# Fix event loop conflicts in Colab\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "9M0_WDziUJjO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 API Key Setup"
      ],
      "metadata": {
        "id": "p43QyjfpUZ-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini API Key setup in Colab secret\n",
        "try:\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not API_KEY:\n",
        "        raise ValueError(\"GEMINI_API_KEY not found in Colab Secrets. Please set it.\")\n",
        "    # Set the official environment variable name required by the Google GenAI SDK\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = API_KEY\n",
        "    print(\"‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Warning: Could not load API Key from Colab Secrets: {e}\")\n",
        "    print(\"Please ensure your API Key is set as a Colab secret named 'GEMINI_API_KEY' or set the environment variable manually.\")\n",
        "    # Fallback/Manual setting (Uncomment and replace if Colab Secrets is not used)\n",
        "    # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_MANUAL_API_KEY\""
      ],
      "metadata": {
        "id": "0InllCONUggj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846e38bf-4e33-4896-b2d9-7cee312b3559"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Document Upload"
      ],
      "metadata": {
        "id": "zF41iRd_UmH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = None\n",
        "if uploaded:\n",
        "    pdf_path = list(uploaded.keys())[0]\n",
        "    print(f\"Successfully uploaded: {pdf_path}\")\n",
        "else:\n",
        "    print(\"No file was uploaded. Exiting.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "BjWKUUkIUp6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "72c20300-72b3-4497-f9b8-97521f40b10a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f83b18b5-4512-41be-ba16-d471439e8a1f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f83b18b5-4512-41be-ba16-d471439e8a1f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving LenderFeesWorksheetNew.pdf to LenderFeesWorksheetNew (1).pdf\n",
            "Successfully uploaded: LenderFeesWorksheetNew (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Custom PyMuPDF Loader Function (PDF Parsing)"
      ],
      "metadata": {
        "id": "bh0AOQB7nvmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_with_pymupdf(pdf_path: str) -> List[Document]:\n",
        "    \"\"\"Load a PDF and convert it to LlamaIndex Document format using PyMuPDF.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    documents = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "        if not text.strip(): continue # Skip empty pages\n",
        "        documents.append(\n",
        "            Document(text=text, metadata={\"file_name\": os.path.basename(pdf_path), \"page_number\": i + 1})\n",
        "        )\n",
        "    doc.close()\n",
        "    print(f\"Processed {pdf_path}: Extracted {len(documents)} pages with content.\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "H0kFuz4Rn7Q3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Configure RAG Pipeline (LLM, Embeddings, Chunking)"
      ],
      "metadata": {
        "id": "YqYMeoCroEGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Configuring LlamaIndex Settings ---\")\n",
        "# LLM: Gemini 2.5 Flash\n",
        "llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
        "Settings.llm = llm\n",
        "\n",
        "# Embedding Model: HuggingFace all-MiniLM-L6-v2 (Efficient and Local)\n",
        "# Hugging Face API Key setup in Colab Secret\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Chunking Strategy: SentenceSplitter with optimal settings\n",
        "Settings.text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "id": "5mtgoZ_aoNqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f27ec4c7-8b0b-438f-862c-23d577111f65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Configuring LlamaIndex Settings ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1179820267.py:3: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Indexing and Index Creation"
      ],
      "metadata": {
        "id": "7F7-so82oU_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_pdf_with_pymupdf(pdf_path)\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "print(\"‚úÖ Indexing complete. RAG VectorStoreIndex created.\")"
      ],
      "metadata": {
        "id": "pvoRfyFRog9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a123e564-b1b5-4f87-b485-a0f2dc8900f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed LenderFeesWorksheetNew (1).pdf: Extracted 1 pages with content.\n",
            "‚úÖ Indexing complete. RAG VectorStoreIndex created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method**"
      ],
      "metadata": {
        "id": "2lo9ffUJSzJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üî¢ Embedding Model**\n",
        "\n",
        "**Model:** `sentence-transformers/all-MiniLM-L6-v2`\n",
        "<br><br>\n",
        "\n",
        "**Justification:** This model is an extremely efficient, small, and fast open-source embedding model. It provides a good balance of accuracy and speed, making it highly suitable for rapid RAG development in a Colab environment. Running a local HuggingFace model also helps to reduce API costs and latency compared to calling a remote embedding service.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ggWcI5nj0vzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **‚úÇÔ∏è Chunking Strategy**\n",
        "\n",
        "**Strategy:** `SentenceSplitter` with `chunk_size = 512` and `chunk_overlap = 20`.\n",
        "<br><br>\n",
        "\n",
        "**Justification:** The `SentenceSplitter` breaks text primarily at logical sentence boundaries, which is ideal for a semi-structured document like a financial worksheet.\n",
        "\n",
        "  * **Chunk Size (512 tokens):** Provides enough context for the LLM to perform calculations or detailed analysis from the retrieved text.\n",
        "  \n",
        "  * **Overlap (20 tokens):** A small overlap ensures that the context is maintained across the split points, preventing critical information from being cut off.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoIn097P19eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üîç Retrieval Method**\n",
        "\n",
        "**Method:** **Vector Retrieval** (Semantic Search)\n",
        "<br><br>\n",
        "\n",
        "**Justification:** Vector retrieval is used because it finds relevant document segments based on the semantic mening of the query. This is essential for documents where specific financial terms might be used (e.g., \"lender's title insurance\") that a user might query using a different phrase (e.g., \"fee to protect the lender's interest\").\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kFxgX4_l3Zwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Create Query Engine and Execute Prompts**"
      ],
      "metadata": {
        "id": "KZt_12xPS5hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Create Chat Engine"
      ],
      "metadata": {
        "id": "B_9DrGkNxFQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the ChatEngine to maintain conversation history while retrieving context\n",
        "# from your index for each turn.\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"condense_plus_context\", # A common mode for RAG chat\n",
        "    similarity_top_k=3\n",
        ")"
      ],
      "metadata": {
        "id": "DpwmuqyAxL9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Interactive Chat Loop"
      ],
      "metadata": {
        "id": "zxAruhrJyeHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_rag_chatbot():\n",
        "    \"\"\"\n",
        "    An interactive chatbot that grounds its answers using the RAG pipeline.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- üí¨ Interactive RAG Chatbot üí¨ ---\")\n",
        "    print(f\"Document: {pdf_path}\")\n",
        "    print(\"Ask me questions about the document (e.g., 'What is the total estimated monthly payment?').\")\n",
        "    print(\"Type 'exit' to end the conversation.\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Use input() within a try/except to handle unexpected Colab issues\n",
        "            user_input = input(\"You: \")\n",
        "        except EOFError:\n",
        "            # This often catches issues when input is expected but not provided interactively\n",
        "            print(\"\\nExiting due to non-interactive environment.\")\n",
        "            break\n",
        "\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"\\nChatbot: Goodbye! Feel free to upload a new document next time.\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # Use the chat_engine which handles history and retrieval simultaneously\n",
        "            response = chat_engine.chat(user_input)\n",
        "\n",
        "            # Print the response\n",
        "            print(f\"\\nChatbot: {response.response}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing query: {e}\")\n",
        "            print(\"Please try again.\")"
      ],
      "metadata": {
        "id": "reFbq0GZyc9K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Run the chatbot"
      ],
      "metadata": {
        "id": "wIfn7bGazZ7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_rag_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6xhwdwTzgo0",
        "outputId": "57a8408a-3afa-4590-e23a-3bd4bc81c8c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üí¨ Interactive RAG Chatbot üí¨ ---\n",
            "Document: LenderFeesWorksheetNew (1).pdf\n",
            "Ask me questions about the document (e.g., 'What is the total estimated monthly payment?').\n",
            "Type 'exit' to end the conversation.\n",
            "------------------------------------------------------------\n",
            "You: What is the total estimated montly payment\n",
            "\n",
            "Chatbot: The total estimated monthly payment is $1,869.37. This amount is broken down into several components:\n",
            "\n",
            "*   **Principal & Interest:** $2,308.95 (This seems to be a typo in the document where the total monthly payment is less than the P&I listed, but I'm providing the exact details from the document.)\n",
            "*   **Hazard Insurance:** $39.58\n",
            "*   **Real Estate Taxes:** $400.00\n",
            "*   **Mortgage Insurance:** $0.00\n",
            "*   **Homeowner Assn. Dues:** $0.00\n",
            "*   **Other Financing (P & I):** $0.00\n",
            "*   **Other:** $0.00\n",
            "\n",
            "The document also notes that your actual rate, payment, and cost could be higher, and it recommends getting an official Loan Estimate before choosing a loan.\n",
            "You: Lender's title insurance\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (1).pdf\" document, the Lender's Title Insurance is listed as a fee.\n",
            "\n",
            "Here are the details:\n",
            "*   **Fee:** Lender's Title Insurance\n",
            "*   **Paid To:** The document does not explicitly state who the Lender's Title Insurance is paid to, only that it is a fee.\n",
            "*   **Paid By:** Borrower\n",
            "*   **Amount:** $650.00\n",
            "You: fee to protect the lender interest\n",
            "\n",
            "Chatbot: Based on the \"LenderFeesWorksheetNew (1).pdf\" document, there are several fees that directly or indirectly serve to protect the lender's interest in the loan and the property.\n",
            "\n",
            "Here's a detailed breakdown of such fees:\n",
            "\n",
            "1.  **Lender's Title Insurance:**\n",
            "    *   **Amount:** $650.00\n",
            "    *   **Purpose:** This is a crucial fee specifically designed to protect the lender. It insures the lender against losses arising from defects in the title to the property, such as liens, encumbrances, or other title issues that might not have been discovered during the title search. This ensures the lender's priority lien position on the property.\n",
            "\n",
            "2.  **Appraisal Fee:**\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Amount:** $525.00\n",
            "    *   **Purpose:** While paid by the borrower, the appraisal is conducted to determine the market value of the property. This protects the lender by ensuring that the property serves as adequate collateral for the loan amount, mitigating risk in case of default.\n",
            "\n",
            "3.  **Credit Report Fee:**\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Amount:** $25.00\n",
            "    *   **Purpose:** This fee covers the cost of obtaining the borrower's credit history. It allows the lender to assess the borrower's creditworthiness and ability to repay the loan, thereby protecting the lender from potential default risk.\n",
            "\n",
            "4.  **Tax Service Fee:**\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Amount:** $80.00\n",
            "    *   **Purpose:** This fee ensures that property taxes are monitored and paid. This protects the lender's interest by preventing tax liens from being placed on the property, which could take precedence over the lender's mortgage lien.\n",
            "\n",
            "5.  **Flood Certification Fee:**\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Amount:** $20.00\n",
            "    *   **Purpose:** This fee determines if the property is located in a flood zone. If it is, the lender will typically require flood insurance, which protects the property (and thus the lender's collateral) from flood damage.\n",
            "\n",
            "6.  **Hazard Insurance Premium:**\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Amount:** $475.00 (for 12 months)\n",
            "    *   **Purpose:** This insurance protects the property from physical damage due to events like fire, storms, etc. The lender requires this to protect their collateral (the home) from damage, ensuring its value is maintained.\n",
            "\n",
            "7.  **Underwriting Fee:**\n",
            "    *   **Paid To:** XYZ Lender\n",
            "    *   **Paid By:** Borrower\n",
            "    *   **Amount:** $550.00\n",
            "    *   **Purpose:** This fee covers the lender's cost of evaluating and verifying the loan application, including assessing the borrower's credit, income, assets, and the property's value. It's a comprehensive risk assessment process designed to protect the lender from making a risky loan.\n",
            "\n",
            "In summary, while many fees contribute to the overall loan process, the **Lender's Title Insurance** is the most direct fee specifically named for protecting the lender's interest in the property's title. Other fees like the Appraisal Fee, Credit Report Fee, Tax Service Fee, Flood Certification Fee, Hazard Insurance Premium, and Underwriting Fee also play significant roles in protecting the lender's financial interest and collateral.\n",
            "You: exit\n",
            "\n",
            "Chatbot: Goodbye! Feel free to upload a new document next time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2v1OebJ3KZ9"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}