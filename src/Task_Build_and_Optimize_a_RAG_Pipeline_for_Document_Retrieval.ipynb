{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP15ixmiY/WS0ZyTRlCH9/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LashawnFofung/RAG-Pipelines/blob/main/src/Task_Build_and_Optimize_a_RAG_Pipeline_for_Document_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìë Build And Optimize A RAG Pipeline For Document Retrieval**\n",
        "\n",
        "**Data:** *LenderFeesWorksheetNew.pdf*\n",
        "<br><br>\n",
        "\n",
        "\n",
        "This Colab notebook sets up a Retrieval-Augmented Generation (RAG) system designed to answer questions about the uploaded LenderFeesWorksheetNew.pdf.\n",
        "<br><br>\n",
        "\n",
        "It works by first using PyMuPDF to accurately extract (parse) the text from the PDF. This text is then broken down into smaller, meaningful chunks (‚úÇÔ∏è) and converted into numerical vectors (üî¢) using the efficient `all-MiniLM-L6-v2` HuggingFace embedding model. These vectors are stored in a Vector Index. When you ask a question, the system searches the index to retrieve (üîç) the most relevant text chunks (Vector Retrieval) and feeds both the question and those chunks to the Gemini 2.5 Flash LLM. The LLM then reads the retrieved context and generates a precise answer, such as calculating the total monthly payment or identifying specific fees.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "\n",
        "**Table of Contents**\n",
        "* [1. RAG Pipeline](#scrollTo=Bfr8FNjnSvW8&line=1&uniqifier=1)\n",
        "  * [1.1 Installation](#scrollTo=CVLftbBrTtJD&line=1&uniqifier=1)\n",
        "  * [1.2 Setup Environment and Imports](#scrollTo=A-7Tha4LT_Wp&line=1&uniqifier=1)\n",
        "  * [1.3 API Key Setup](#scrollTo=p43QyjfpUZ-k&line=1&uniqifier=1)\n",
        "  * [1.4 Document Upload](#scrollTo=zF41iRd_UmH7&line=1&uniqifier=1)\n",
        "  * [1.5 Custom PyMuPDF Loader Function (PDF Parsing)](#scrollTo=bh0AOQB7nvmp&line=1&uniqifier=1)\n",
        "  * [1.6 Configure RAG Pipeline (LLM, Embedding, Chunking)](#scrollTo=YqYMeoCroEGh&line=1&uniqifier=1)\n",
        "  * [1.7 Indexing and Index Creation](#scrollTo=7F7-so82oU_z&line=1&uniqifier=1)\n",
        "* [2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method](#scrollTo=2lo9ffUJSzJE&line=1&uniqifier=1)\n",
        "* [3. Create Query Engine and Execute Prompts](#scrollTo=KZt_12xPS5hx)\n",
        "  * [Prompt 1: \"What is the total estimated monthly payment?\"](#scrollTo=Jv-P-qLLVPeG&line=1&uniqifier=1)\n",
        "  * [Prompt 2: \"How much does the borrower pay for lender's title insurance?\"](#scrollTo=a2xtjKotVX_d)"
      ],
      "metadata": {
        "id": "6PmIjtzqPkDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. RAG Pipeline**"
      ],
      "metadata": {
        "id": "Bfr8FNjnSvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Installation"
      ],
      "metadata": {
        "id": "CVLftbBrTtJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install LlamaIndex core, Gemini LLM connector, PyMuPDF, and HuggingFace Embedding integration\n",
        "!pip install -q llama-index llama-index-llms-gemini pymupdf llama-index-embeddings-huggingface nest_asyncio sentence-transformers"
      ],
      "metadata": {
        "id": "H8BUJNkyT0LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Setup Environment and Imports"
      ],
      "metadata": {
        "id": "A-7Tha4LT_Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz # PyMuPDF\n",
        "from google.colab import files, userdata\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from typing import List\n",
        "import nest_asyncio\n",
        "\n",
        "# Fix event loop conflicts in Colab\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "9M0_WDziUJjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 API Key Setup"
      ],
      "metadata": {
        "id": "p43QyjfpUZ-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini API Key setup in Colab secret\n",
        "try:\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not API_KEY:\n",
        "        raise ValueError(\"GEMINI_API_KEY not found in Colab Secrets. Please set it.\")\n",
        "    # Set the official environment variable name required by the Google GenAI SDK\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = API_KEY\n",
        "    print(\"‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Warning: Could not load API Key from Colab Secrets: {e}\")\n",
        "    print(\"Please ensure your API Key is set as a Colab secret named 'GEMINI_API_KEY' or set the environment variable manually.\")\n",
        "    # Fallback/Manual setting (Uncomment and replace if Colab Secrets is not used)\n",
        "    # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_MANUAL_API_KEY\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0InllCONUggj",
        "outputId": "ff392527-9862-4339-e4ea-e4b1ad32fb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key successfully loaded and set as GOOGLE_API_KEY.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Document Upload"
      ],
      "metadata": {
        "id": "zF41iRd_UmH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = None\n",
        "if uploaded:\n",
        "    pdf_path = list(uploaded.keys())[0]\n",
        "    print(f\"Successfully uploaded: {pdf_path}\")\n",
        "else:\n",
        "    print(\"No file was uploaded. Exiting.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "BjWKUUkIUp6W",
        "outputId": "f4668486-97c9-42a1-a9fe-357a8ce641e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Uploading Document: 'LenderFeesWorksheetNew.pdf' ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f8b209d-b9f2-41ca-b28f-2283236ba60a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6f8b209d-b9f2-41ca-b28f-2283236ba60a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving LenderFeesWorksheetNew.pdf to LenderFeesWorksheetNew (2).pdf\n",
            "Successfully uploaded: LenderFeesWorksheetNew (2).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Custom PyMuPDF Loader Function (PDF Parsing)"
      ],
      "metadata": {
        "id": "bh0AOQB7nvmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_with_pymupdf(pdf_path: str) -> List[Document]:\n",
        "    \"\"\"Load a PDF and convert it to LlamaIndex Document format using PyMuPDF.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    documents = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "        if not text.strip(): continue # Skip empty pages\n",
        "        documents.append(\n",
        "            Document(text=text, metadata={\"file_name\": os.path.basename(pdf_path), \"page_number\": i + 1})\n",
        "        )\n",
        "    doc.close()\n",
        "    print(f\"Processed {pdf_path}: Extracted {len(documents)} pages with content.\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "H0kFuz4Rn7Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Configure RAG Pipeline (LLM, Embeddings, Chunking)"
      ],
      "metadata": {
        "id": "YqYMeoCroEGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Configuring LlamaIndex Settings ---\")\n",
        "# LLM: Gemini 2.5 Flash\n",
        "llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
        "Settings.llm = llm\n",
        "\n",
        "# Embedding Model: HuggingFace all-MiniLM-L6-v2 (Efficient and Local)\n",
        "# Hugging Face API Key setup in Colab Secret\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Chunking Strategy: SentenceSplitter with optimal settings\n",
        "Settings.text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5mtgoZ_aoNqP",
        "outputId": "41695169-9f87-44d2-9f55-3b42ae830726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Configuring LlamaIndex Settings ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3859728630.py:3: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  llm = Gemini(model=\"models/gemini-2.5-flash\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Indexing and Index Creation"
      ],
      "metadata": {
        "id": "7F7-so82oU_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_pdf_with_pymupdf(pdf_path)\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "print(\"‚úÖ Indexing complete. RAG VectorStoreIndex created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvoRfyFRog9X",
        "outputId": "ffe5d0cc-09de-4ca7-f22b-2b23809b3f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed LenderFeesWorksheetNew (2).pdf: Extracted 1 pages with content.\n",
            "‚úÖ Indexing complete. RAG VectorStoreIndex created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Reasons for Methods: Embedding, Chunking Strategy, & Retrieval Method**"
      ],
      "metadata": {
        "id": "2lo9ffUJSzJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üî¢ Embedding Model**\n",
        "\n",
        "**Model:** `sentence-transformers/all-MiniLM-L6-v2`\n",
        "<br><br>\n",
        "\n",
        "**Justification:** This model is an extremely efficient, small, and fast open-source embedding model. It provides a good balance of accuracy and speed, making it highly suitable for rapid RAG development in a Colab environment. Running a local HuggingFace model also helps to reduce API costs and latency compared to calling a remote embedding service.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ggWcI5nj0vzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **‚úÇÔ∏è Chunking Strategy**\n",
        "\n",
        "**Strategy:** `SentenceSplitter` with `chunk_size = 512` and `chunk_overlap = 20`.\n",
        "<br><br>\n",
        "\n",
        "**Justification:** The `SentenceSplitter` breaks text primarily at logical sentence boundaries, which is ideal for a semi-structured document like a financial worksheet.\n",
        "\n",
        "  * **Chunk Size (512 tokens):** Provides enough context for the LLM to perform calculations or detailed analysis from the retrieved text.\n",
        "  \n",
        "  * **Overlap (20 tokens):** A small overlap ensures that the context is maintained across the split points, preventing critical information from being cut off.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoIn097P19eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üîç Retrieval Method**\n",
        "\n",
        "**Method:** **Vector Retrieval** (Semantic Search)\n",
        "<br><br>\n",
        "\n",
        "**Justification:** Vector retrieval is used because it finds relevant document segments based on the semantic mening of the query. This is essential for documents where specific financial terms might be used (e.g., \"lender's title insurance\") that a user might query using a different phrase (e.g., \"fee to protect the lender's interest\").\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kFxgX4_l3Zwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Create Query Engine and Execute Prompts**"
      ],
      "metadata": {
        "id": "KZt_12xPS5hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Query Engine"
      ],
      "metadata": {
        "id": "B_9DrGkNxFQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=2)\n",
        "\n",
        "print(\"\\n--- Step 4: Query Results ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpwmuqyAxL9k",
        "outputId": "15209c39-4318-4fe9-dc3e-d15856cd9db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Query Results ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 1: \"What is the total estimated monthly payment?\""
      ],
      "metadata": {
        "id": "Jv-P-qLLVPeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = \"What is the total estimated monthly payment?\"\n",
        "print(f\"Prompt 1: \\\"{prompt_1}\\\"\")\n",
        "response_1 = query_engine.query(prompt_1)\n",
        "print(f\"Response 1: {response_1.response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "bbzZYk32VWnH",
        "outputId": "8d16cbad-c0c0-4d5c-cdbb-16f2217bdf47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt 1: \"What is the total estimated monthly payment?\"\n",
            "Response 1: The total estimated monthly payment is $1,869.37.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total estimated monthly payment is the sum of the Principal & Interest and any recurring monthly escrow items.\n",
        "\n",
        "\n",
        "* Principal & Interest (P&I)\n",
        "  * $1,869.58\twas found in the \"TOTAL ESTIMATED MONTHLY PAYMENT\" section.\n",
        "\n",
        "* Hazard Insurance (Monthly)\n",
        "  * $39.58\n",
        "\n",
        "  * The document lists a 12-month premium of $475.00\n",
        "\n",
        "  * Calculated $39.58 x 12 mth(s)\n",
        "\n",
        "* Total Estimated Monthly Payment\n",
        "  * $1,909.16\n",
        "\n",
        "  * Calculated by adding ($1,869.58 + $39.58)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "10y9_8l1yCvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 2: \"How much does the borrower pay for lender's title insurance?\""
      ],
      "metadata": {
        "id": "a2xtjKotVX_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 2\n",
        "prompt_2 = \"How much does the borrower pay for lender's title insurance?\"\n",
        "print(f\"Prompt 2: \\\"{prompt_2}\\\"\")\n",
        "response_2 = query_engine.query(prompt_2)\n",
        "print(f\"Response 2: {response_2.response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "x7tPcnsfVgei",
        "outputId": "2a755586-05a3-495d-e49d-0054e780804a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt 2: \"How much does the borrower pay for lender's title insurance?\"\n",
            "Response 2: The borrower pays $650.00 for Lender's Title Insurance.\n"
          ]
        }
      ]
    }
  ]
}